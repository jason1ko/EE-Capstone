# -*- coding: utf-8 -*-
"""verification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pgYGVG83typo7SwnKcY4vh2Muxx0SAFy
"""

import os
import time
import numpy as np
import pickle
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.nn.parallel
import torch.optim
import torch.utils.data
import torch.backends.cudnn as cudnn
import networks as networks
import shared_networks as shared_networks
from collections import OrderedDict
import matplotlib.pyplot as plt
import dload
from torch.utils.tensorboard import SummaryWriter
from utils import *
import json
import torchvision.transforms as transforms
import torch.utils.data as data
from PIL import Image
from sklearn.metrics import roc_auc_score, plot_roc_curve, roc_curve
from scipy import interp


torch.backends.cudnn.enabled = True
torch.cuda.set_device(0)

exp = '15'
epoch = '70'

print(exp)

root_dir = os.path.join('results', 'exp_'+exp)
model_dir = os.path.join(root_dir, 'models')
figure_dir = os.path.join(root_dir, 'figures', epoch, 'ocular')

makedir(root_dir)
makedir(model_dir)
makedir(figure_dir)

batch_size = 500
embedding_size = 512
nof_train_iden = 1054

model = shared_networks.shared_network(num_classes=1054)
# model = shared_networks.shared_network_v2(num_classes=1054)
if exp == '05' or exp == '06' or exp == '15':
    model = networks.O_net(num_classes=1054)
## load model
model.load_state_dict(torch.load(os.path.join(model_dir, 'model_'+epoch+'.pth.tar'), map_location='cpu')['state_dict'])
model = model.cuda()
model.eval()

eer_dict = {'val':0, 'ethnic':0, 'pubfig':0, 'facescrub':0,'wiki':0, 'ar': 0, 'ytf':0}

dset_list = ['ethnic', 'pubfig', 'facescrub', 'imdb_wiki', 'ar', 'ytf']

ver_img_per_class = 4

def compute_eer(fpr,tpr):
    """ Returns equal error rate (EER) and the corresponding threshold. """
    fnr = 1-tpr
    abs_diffs = np.abs(fpr - fnr)
    min_index = np.argmin(abs_diffs)
    eer = np.mean((fpr[min_index], fnr[min_index]))
    return eer


class dataset(data.Dataset):
    def __init__(self, dset, dset_type='gallery'):
        if dset == 'ethnic':
            self.ocular_root_dir = os.path.join('/home/yoon/datasets/face_ocular', dset, 'Recognition', dset_type)
        else:
            self.ocular_root_dir = os.path.join('/home/yoon/datasets/face_ocular', dset, dset_type)
        self.nof_identity = len(os.listdir(self.ocular_root_dir)) # number of folders in 'gallery' or 'probe'
        self.ocular_img_dir_list = []
        self.label_list = []
        self.label_dict = {}
        cnt = 0
        for iden in sorted(os.listdir(self.ocular_root_dir)):
            ver_img_cnt = 0
            for i in range(ver_img_per_class): # 4 iterations
                list_img = sorted(os.listdir(os.path.join(self.ocular_root_dir, iden, 'periocular')))
                list_len = len(list_img)
                offset = list_len // ver_img_per_class
                self.ocular_img_dir_list.append(os.path.join(self.ocular_root_dir, iden, 'periocular', list_img[offset*i]))
                self.label_list.append(cnt) # [0,0,0,0, 1,1,1,1, 2,2,2,2, ...]
                ver_img_cnt += 1
                if ver_img_cnt == ver_img_per_class:
                    break
            cnt += 1

        self.onehot_label = np.zeros((len(self.ocular_img_dir_list), self.nof_identity)) # 4 * 1
        for i in range(len(self.ocular_img_dir_list)):
            self.onehot_label[i, self.label_list[i]] = 1

        self.ocular_transform = transforms.Compose([transforms.Resize((48, 128)),
                                                 transforms.ToTensor(),
                                                 transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                                                      std=[0.5, 0.5, 0.5])])

    def __len__(self):
        return len(self.ocular_img_dir_list) # same as len(self.label_list)

    def __getitem__(self, idx):
        ocular = Image.open(self.ocular_img_dir_list[idx])
        ocular = self.ocular_transform(ocular)
        onehot = self.onehot_label[idx] # idx'th row(line) of onehot_label matrix
        return ocular, onehot


for dset_name in dset_list:
    embedding_size = 512 # why 512 ?? bcz the bn5 layer of sharednetwork ends with 512

    if dset_name == 'ethnic':
        dset = dataset(dset=dset_name, dset_type='probe')
    else:
        dset = dataset(dset=dset_name, dset_type='gallery')
    dloader = torch.utils.data.DataLoader(dset, batch_size=batch_size, num_workers=4)
    nof_dset = len(dset)
    nof_iden = dset.nof_identity # number of folders in 'gallery' or 'probe'
    embedding_mat = torch.zeros((nof_dset, embedding_size)).cuda()
    label_mat = torch.zeros((nof_dset, nof_iden)).cuda() # size is same as onehot_label


    start = time.time()
    with torch.no_grad(): # image
        for i, (image, onehot) in enumerate(dloader): # dloader (guessed) ocu, face, label. i = len(dloader) // batchsize
                                                      # onehot is estimated to be ?? * nof_iden
            nof_img = image.shape[0] # same as batch size
            image = image.cuda()
            onehot = onehot.cuda()

            feature = model.get_ocular_feature(image)

            embedding_mat[i*batch_size:i*batch_size+nof_img, :] = feature.detach().clone()
            label_mat[i*batch_size:i*batch_size+nof_img, :] = onehot # adding  batchsize*nof_iden 'onehot' matrix to 'nof_img' times.
                                                                     # same as onehot_label defined in dataset???
        ### roc
        embedding_mat /= torch.norm(embedding_mat, p=2, dim=1, keepdim=True) # p = 2 is the default. general norm.
                                                                             # nof_dset * embedding_size => nof_dset * 1d
                                                                             # to make each (row)line of embedding_mat the absol value is 1
        score_mat = torch.matmul(embedding_mat, embedding_mat.t()).cpu() # diagonal of which is all 1.
        gen_mat = torch.matmul(label_mat, label_mat.t()).cpu()
        gen_r, gen_c = torch.where(gen_mat == 1)
        imp_r, imp_c = torch.where(gen_mat == 0)

        gen_score = score_mat[gen_r, gen_c].cpu().numpy()
        imp_score = score_mat[imp_r, imp_c].cpu().numpy()

        y_gen = np.ones(gen_score.shape[0])
        y_imp = np.zeros(imp_score.shape[0])

        score = np.concatenate((gen_score, imp_score))
        y = np.concatenate((y_gen, y_imp))


        fpr_tmp, tpr_tmp, _ = roc_curve(y, score)
        eer_dict[dset_name] = compute_eer(fpr_tmp, tpr_tmp)

        print(eer_dict[dset_name] * 100)